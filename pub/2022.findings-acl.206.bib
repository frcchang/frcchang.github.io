@inproceedings{du-etal-2022-graph,
    title = "A Graph Enhanced {BERT} Model for Event Prediction",
    author = "Du, Li  and
      Ding, Xiao  and
      Zhang, Yue  and
      Liu, Ting  and
      Qin, Bing",
    booktitle = "Findings of the Association for Computational Linguistics: ACL 2022",
    month = may,
    year = "2022",
    address = "Dublin, Ireland",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.findings-acl.206",
    doi = "10.18653/v1/2022.findings-acl.206",
    pages = "2628--2638",
    abstract = "Predicting the subsequent event for an existing event context is an important but challenging task, as it requires understanding the underlying relationship between events. Previous methods propose to retrieve relational features from event graph to enhance the modeling of event correlation. However, the sparsity of event graph may restrict the acquisition of relevant graph information, and hence influence the model performance. To address this issue, we consider automatically building of event graph using a BERT model. To this end, we incorporate an additional structured variable into BERT to learn to predict the event connections in the training process.Hence, in the test process, the connection relationship for unseen events can be predicted by the structured variable.Results on two event prediction tasks: script event prediction and story ending prediction, show that our approach can outperform state-of-the-art baseline methods.",
}
