@ARTICLE{duan2019tend,
  author={J. {Duan} and X. {Ding} and Y. {Zhang} and T. {Liu}},
  journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing}, 
  title={TEND: A Target-Dependent Representation Learning Framework for News Document}, 
  year={2019},
  volume={27},
  number={12},
  pages={2313-2325},
  abstract={Real-time news documents published on the Internet have global financial and political impacts. Pioneering statistical approaches investigate manually defined features to capture lexical, sentiment, and event information, which suffer from feature sparsity. As a remedy, recent work has considered learning dense vector representations for documents. Such representations are general, which can not model target-dependent scenarios, such as stance detection towards a specific claim. There has been work on target-specific word and sentence representations, but little was done on target-dependent document representation. Moreover, documents contain more potentially helpful information, but also noise compared to events and sentences. To address the above issues, we focus on models that are: 1. task-driven, which optimize the neural network representations for the end task; 2. target-specific, learning news representations by considering the influence of specific targets. In particular, we propose a novel document-level target-dependent learning framework TEND. The framework employs the information of the target and the news abstract as clues, obtaining relatively informative sentences from the entire document for our objectives. The framework assembles a document representation by integrating the news abstract representation and a weighted sum of sentence representations in the document. To the best of our knowledge, we are among the first to investigate target-dependent document representation. Existing text representation models can be easily integrated into our TEND framework, and it is general enough to be applied to different target-dependent document representation tasks. We empirically evaluate our framework on two target-dependent document-level tasks, including a cumulative abnormal return prediction task and a news stance detection task. Results show that our models give the best performances compared to state-of-the-art document embedding methods, yielding robust and consistent performances across datasets.},
  keywords={Internet;learning (artificial intelligence);neural nets;statistical analysis;text analysis;target-dependent document-level tasks;news stance detection task;real-time news documents;dense vector representations;target-dependent scenarios;target-specific word;sentence representations;neural network representations;news representations;informative sentences;news abstract representation;text representation models;document-level target-dependent learning framework;target-dependent document representation tasks;Internet;Task analysis;Text mining;Twitter;Speech processing;Logic gates;Internet;Neural networks;Stock Market Prediction;Target-dependent Representation;Document Representation;Stance Detection},
  doi={10.1109/TASLP.2019.2947364},
  ISSN={2329-9304},
  month={Dec},}
